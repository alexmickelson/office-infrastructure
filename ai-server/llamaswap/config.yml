models:
  "gpt-oss-120b":
    cmd: |
      ./llama-server \
      --port ${PORT} \
      -m models/gpt-oss-120b-F16.gguf \
      --ctx-size 0 --jinja -ub 2048 -b 2048
    # --ctx-size 32768 --jinja -ub 4096 -b 4096
    # --jinja --ctx-size 16384
    aliases:
      - "gpt-oss:120b"

  # "gemma3-27b":
  #   cmd: |
  #     ./llama-server \
  #     --port ${PORT} \
  #     -m models/gemma-3-27b-it-Q2_K_L.gguf \
  #     --mmproj models/gemma-mmproj-F16.gguf \
  #     --ctx-size 0 
  #   # -m models/gemma-3-27b-it-UD-Q4_K_XL.gguf \
  #   aliases:
  #     - "gemma3:27b"
  #   ttl: 300
